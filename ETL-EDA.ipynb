{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL y EDA sobre el dataset de steam_games para el Proyecto ML Ops de Henry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema de negocio:\n",
    "Se solicita predecir el precio de un videojuego. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:\n",
    "Habiendo probado la primera limpieza de los datos (utilizada exitósamente sobre el main.py), debemos investigar las relaciones que hay entre las variables del dataset, comprobar si hay outliers o anomalías, y verificar patrones interesantes que valgan la pena explorar para crear un modelo predictivo eficiente. Este deberá basarse en características como Género, Año, Metascore o cualquiera de aquellas que resulten adecuadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describimos las variables que conforman el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* publisher: Empresa publicadora del contenido\n",
    "* genres: Género del contenido\n",
    "* app_name: Nombre del contenido\n",
    "* title: Título del contenido\n",
    "* url: URL de publicación del contenido\n",
    "* release_date: Fecha de lanzamiento\n",
    "* tags: Etiquetas de contenido\n",
    "* discount_price: Precio de descuento\n",
    "* reviews_url: Reviews de contenido\n",
    "* specs: Especificaciones\n",
    "* price: Precio del contenido\n",
    "* early_access: Acceso temprano\n",
    "* id: Identificador único de contenido\n",
    "* developer: Desarrollador\n",
    "* sentiment: Análisis de sentimientos\n",
    "* metascore: Score por metacritic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación del primer Data Wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos de las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperamos los datos desde el archivo .json provisto\n",
    "dataset = []\n",
    "with open('dataset/steam_games.json') as f:\n",
    "    dataset.extend(ast.literal_eval(line) for line in f)\n",
    "    \n",
    "# Creamos el dataframe a partir del dataset obtenido\n",
    "data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la estructura de nuestro dataframe\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos cómo está conformado\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una comprobación de los valores nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reubicamos la variable 'id' para un mejor lectura\n",
    "cols = list(data.columns)\n",
    "cols.remove('id')\n",
    "cols = ['id'] + cols\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si la variable 'id' contiene nulos\n",
    "filas_null = data[data['id'].isna()]\n",
    "filas_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos las filas duplicadas en la variable 'id'\n",
    "filas_dup = data[data.duplicated('id', keep=False)]\n",
    "filas_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas con nulos y duplicadas en la variable 'id'\n",
    "data_con_valores_nuevos = data.copy()\n",
    "data_con_valores_nuevos.drop([74, 14573], inplace=True)\n",
    "data_con_valores_nuevos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adecuamos el valor nulo en la variable 'id' en correlación a los demás valores existentes\n",
    "filas_con_nulos = data_con_valores_nuevos[data_con_valores_nuevos['id'].isnull()].index\n",
    "valores_no_nulos_ordenados = data_con_valores_nuevos.dropna(subset=['id']).sort_values('id')['id'].unique()\n",
    "data_con_valores_nuevos.loc[filas_con_nulos, 'id'] = valores_no_nulos_ordenados[:len(filas_con_nulos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos nuestro nuevo orden de variables y comprobamos la composición de nuestro dataframe\n",
    "data_con_valores_nuevos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hasta aquí nos hemos asegurado de que el dataframe inicial contenga la información adecuada para comenzar con un análisis sin escollos. Hemos visto que unas de las variables de interés, 'metascore', del total de filas del dataframe, contiene casi un 95% de valores nulos, y que la variable 'id' contenía valores duplicados y nulos, que se han corregido y a su vez fue recolocada para poder utilizarla como identificador único en el caso de querer relacionar la presente información con otros datasets en un análisis ulterior.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adecuación y limpieza del dataframe\n",
    "data_steam = data_con_valores_nuevos.copy()\n",
    "data_steam['release_date'] = pd.to_datetime(data_steam['release_date'], errors='coerce')\n",
    "data_steam['metascore'] = pd.to_numeric(data_steam['metascore'], errors='coerce')\n",
    "data_steam['price'] = pd.to_numeric(data_steam['price'], errors='coerce')\n",
    "reemplazar_valores = {'publisher': '', 'genres': '', 'tags': '', 'discount_price': 0,\n",
    "                      'specs': '', 'reviews_url': '', 'app_name': '', 'title': '',\n",
    "                       'id': '', 'sentiment': '', 'developer': ''}\n",
    "data_steam.fillna(value=reemplazar_valores, inplace=True)\n",
    "data_steam = data_steam.dropna(subset=['price'])\n",
    "data_steam = data_steam.dropna(subset=['release_date'])\n",
    "data_steam = data_steam.dropna(subset=['metascore'])\n",
    "data_steam.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionamos la variable 'price', que más tarde usaremos en nuestro modelo predictor\n",
    "data_steam['price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos limpieza de las variables numéricas\n",
    "data_steam['price'] = data_steam['price'].astype(float)\n",
    "data_steam['metascore'] = data_steam['metascore'].replace('NA', np.nan)\n",
    "data_steam = data_steam.dropna(subset=['metascore'])\n",
    "data_steam['metascore'] = data_steam['metascore'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función para extraer los datos de las variables que contienen listas\n",
    "def extraer_listas(df, columns_to_explode):\n",
    "    data_exploded = df.copy()\n",
    "    for column in columns_to_explode:\n",
    "        data_exploded = data_exploded.explode(column)\n",
    "    data_exploded.reset_index(drop=True, inplace=True)\n",
    "    return data_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos y explotamos las variables de interés\n",
    "col_listas = ['genres', 'tags', 'specs']\n",
    "data_steam_final = extraer_listas(data_steam, col_listas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos los valores únicos por variable\n",
    "data_steam_final.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos el dataframe final\n",
    "data_steam_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con la vista puesta en normalizar los datos entre las distintas variables, se decidió eliminar los datos nulos o faltantes, los cuales eran una constante en todo el dataframe, adecuando también el tipo de dato correcto para cada columna. Asmimismo, se entrajeron los datos contenidos dentro de listas en las variables 'genres', 'specs' y 'tags'. Luego, llegamos al resultado de emparejar la información en todas las variables, logrando que todos los valores coincidan sin nulos o faltantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Componentes Principales (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de las librerías necesarias\n",
    "import category_encoders as ce\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_steam_metascore = data_steam_final.copy()\n",
    "# Codificamos las variables categóricas a numéricas para una mejor utilización del modelo\n",
    "a_numérica = ce.OrdinalEncoder(cols=['id', 'publisher', 'genres', 'app_name', 'title', 'url', 'release_date',\n",
    "       'tags', 'discount_price', 'reviews_url', 'specs', 'price',\n",
    "       'early_access', 'developer', 'sentiment', 'metascore'])\n",
    "\n",
    "# Definimos un dataframe para el cálculo del PCA \n",
    "data_steam_pca = a_numérica.fit_transform(data_steam_metascore)\n",
    "data_steam_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo PCA con escalado de los datos y lo agrupamos en un pipeline\n",
    "pipe_pca = make_pipeline(MinMaxScaler(), PCA())\n",
    "pipe_pca.fit(data_steam_pca)\n",
    "modelo_pca = pipe_pca.named_steps['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el porcentaje de varianza explicada acumulada\n",
    "prop_varianza_acum = modelo_pca.explained_variance_ratio_.cumsum()\n",
    "print(prop_varianza_acum)\n",
    "\n",
    "# Lo mostramos en un gráfico\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "ax.plot(np.arange(len(data_steam_pca.columns)) + 1, prop_varianza_acum, marker = 'o')\n",
    "for x, y in zip(np.arange(len(data_steam_pca.columns)) + 1, prop_varianza_acum):\n",
    "    label = round(y, 2)\n",
    "    ax.annotate(label, (x,y), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_xticks(np.arange(modelo_pca.n_components_) + 1)\n",
    "ax.set_title('Porcentaje de Varianza Explicada Acumulada')\n",
    "ax.set_xlabel('Componente Principal')\n",
    "ax.set_ylabel('% Varianza Acumulada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos ahora un nuevo dataframe para mostrar el trabajo del PCA en columnas\n",
    "pca_df = data_steam_pca\n",
    "pca_df2 = pca_df\n",
    "pca_df = MinMaxScaler().fit_transform(pca_df)\n",
    "pca_df = pd.DataFrame(pca_df,columns=pca_df2.columns).set_index(pca_df2.index)\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a aplicar el PCA y calcular los porcentajes en las muestras explicadas anteriormente\n",
    "pca = PCA(n_components=16)\n",
    "principalComponents = pca.fit_transform(pca_df)\n",
    "principalComp_Df = pd.DataFrame(data = principalComponents, columns = ['pca1','pca2','pca3','pca4','pca5','pca6','pca7','pca8','pca9','pca10','pca11','pca12','pca13','pca14','pca15','pca16']).set_index(pca_df.index)\n",
    "print(\"Forma del dataframe de los Componentes Principales\", principalComp_Df.shape)\n",
    "explicacion = pca.explained_variance_ratio_\n",
    "print(explicacion)\n",
    "print('suma:', sum(explicacion[:16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos el dataframe de PCA logrado\n",
    "principalComp_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Este somero análisis de componentes principales, en la idea de que al reducir la dimensionalidad de nuestro dataframe a un 80/85 porciento de explicación con el mínimo de columnas posibles es suficiente a los fines de nuestro mejor análisis de datos, nos lleva a concluir que acotando nuestro dataframe principal a 6 columnas, tendríamos suficientes componentes principales para llevar el estudio de nuestros datos al éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los datos y visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducimos las variables del dataframe a las de interés\n",
    "steam_eda_reduc = data_steam_final.drop(['id', 'publisher', 'app_name', 'url', 'title', 'reviews_url', 'sentiment'], axis=1, inplace=True)\n",
    "steam_eda_reduc = data_steam_final[data_steam_final['price'] != 0]\n",
    "steam_eda_reduc['genres'] = steam_eda_reduc['genres'].replace('', np.nan)\n",
    "steam_eda_reduc = steam_eda_reduc.dropna(subset=['genres'])\n",
    "steam_eda_reduc.reset_index(drop=True, inplace=True)\n",
    "steam_eda_reduc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nube de palabras para las variables no numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los objetos WordCloud para las variables 'genres', 'tags', 'specs' y 'developer'\n",
    "steam_eda_reduc['genres'] = steam_eda_reduc['genres'].astype(str)\n",
    "all_genres = ','.join(steam_eda_reduc['genres']).lower()\n",
    "wordcloud_genres = WordCloud(width=1200, height=600, background_color='black', colormap='viridis', max_words=100).generate(all_genres)\n",
    "steam_eda_reduc['tags'] = steam_eda_reduc['tags'].astype(str)\n",
    "all_tags = ','.join(steam_eda_reduc['tags']).lower()\n",
    "wordcloud_tags = WordCloud(width=1200, height=600, background_color='black', colormap='viridis', max_words=100).generate(all_tags)\n",
    "steam_eda_reduc['specs'] = steam_eda_reduc['specs'].astype(str)\n",
    "all_specs = ','.join(steam_eda_reduc['specs']).lower()\n",
    "wordcloud_specs = WordCloud(width=1200, height=600, background_color='black', colormap='viridis', max_words=100).generate(all_specs)\n",
    "steam_eda_reduc['developer'] = steam_eda_reduc['developer'].astype(str)\n",
    "all_developers = ','.join(steam_eda_reduc['developer']).lower()\n",
    "wordcloud_developers = WordCloud(width=1200, height=600, background_color='black', colormap='viridis', max_words=100).generate(all_developers)\n",
    "# Definimos subplots con 2 filas y 2 columnas para las nubes de palabras\n",
    "plt.figure(figsize=(15, 12))\n",
    "# Subplot 1: Géneros\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(wordcloud_genres, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Nube de Palabras - Géneros')\n",
    "# Subplot 2: Tags\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(wordcloud_tags, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Nube de Palabras - Etiquetas')\n",
    "# Subplot 3: Specs\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(wordcloud_specs, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Nube de Palabras - Especificaciones')\n",
    "# Subplot 4: Developers\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(wordcloud_developers, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Nube de Palabras - Desarrolladores')\n",
    "# Ajustamos los subplots para evitar superposición de etiquetas\n",
    "plt.tight_layout()\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nótese que entre géneros y etiquetas, Indie y Action mantienen una notable similitud en el primer y segundo puesto, ya no hallándose el mismo patrón para los demás. Ya respecto a las especificaciones, single, player y steam marcan el top 3, mientras que para desarrolladores, al parecer interactive es la palabra más elegida entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matriz de correlación entre la variable 'genres' y las demás numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una copia del dataframe principal\n",
    "steam_eda_corr = steam_eda_reduc.copy()\n",
    "# Codificamos las variables categóricas utilizando one-hot encoding\n",
    "steam_eda_corr = pd.get_dummies(steam_eda_corr, columns=['genres'])\n",
    "# Calculamos la matriz de correlación\n",
    "correlation_matrix = steam_eda_corr.corr()\n",
    "# Creamos la visualización de la matriz de correlación\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interesante es darnos cuenta, luego de analizar la presente matriz, que la variable 'early_access' comparte una correlación por debajo del 0.5 respecto del género denominado (uno pensaría de inmediato que debería ser una correlación perfecta) Early Access, sobresaliendo luego las correlaciones -aunque bajas, presentes- entre los géneros de acción e indie, acción y aventuras e indie y aventuras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crosstab para las variables 'genres' y 'early_access'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe para revisión\n",
    "pd.crosstab(index=steam_eda_reduc['genres'], columns=steam_eda_reduc['early_access'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la visualización de las variables detalladas\n",
    "pd.crosstab(index=steam_eda_reduc['genres'], columns=steam_eda_reduc['early_access']).plot.barh(stacked=True, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sin más, al parecer la plataforma de juegos no es partidaria de accesos tempranos en casi ninguno de sus géneros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Catplot para las variables 'genres' y 'release_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el catplot para las variables detalladas\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.catplot(x='genres', y='release_date', data=steam_eda_reduc, jitter=0.5, hue='genres', palette='Set1', height=10, aspect=2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Género')\n",
    "plt.ylabel('Fecha de lanzamiento')\n",
    "plt.title('Género en relación a su fecha de lanzamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos observar que los géneros casual y aventuras, fueron los primeros en lanzarse, que entre los años 2008 y 2017 se concentran la mayor cantidad de lanzamientos y que Free to Play y Early Access, se pelean por ser el género menos lanzado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Violinplot para las variables 'genres', 'metascore' y 'early_access'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos un tipo de gráfico boxplot para mostrar los resultados del 'describe' \n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.violinplot(data=steam_eda_reduc, x='genres', y='metascore', hue='early_access')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Al contrario de lo que venimos viendo, resulta que el género Acceso Temprano como así el tipo de acceso temprano, aquí batallan mano a mano en cuanto a su metascore, respecto de géneros como acción e indie, con una concentración cercana al puntaje 87, teniendo a su vez como el género con más variación de puntajes a Action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histograma para las variables 'price' y 'metascore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos con una comprobación de la distribución en un pequeño dataframe\n",
    "steam_eda_reduc[['price', 'metascore']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos aseguramos que las variables no contienen valores no numéricos\n",
    "steam_eda_reduc = steam_eda_reduc.dropna(subset=['price', 'metascore'])\n",
    "# Convertir las columnas 'price' y 'metascore' al tipo de datos numérico si es necesario (omitir si ya son numéricas)\n",
    "steam_eda_reduc['price'] = pd.to_numeric(steam_eda_reduc['price'], errors='coerce')\n",
    "steam_eda_reduc['metascore'] = pd.to_numeric(steam_eda_reduc['metascore'], errors='coerce')\n",
    "# Creamos una figura con 1 fila y 2 columnas para los subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Histograma de 'price' en el primer subplot\n",
    "sns.histplot(steam_eda_reduc['price'], bins=100, kde=False, color='gray', ax=ax2)\n",
    "min_price = steam_eda_reduc['price'].min()\n",
    "max_price = steam_eda_reduc['price'].max()\n",
    "ax2.set_xlabel('Precio')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "ax2.set_title('Histograma del Precio de los Videojuegos')\n",
    "ax2.text(0.75, 0.9, f\"Media: {steam_eda_reduc['price'].mean():.2f}\\nMediana: {steam_eda_reduc['price'].median():.2f}\\nDesviación Estándar: {steam_eda_reduc['price'].std():.2f}\",\n",
    "         transform=ax2.transAxes)\n",
    "ax2.axvline(min_price, color='red', linestyle='dashed', linewidth=2, label=f'Mínimo: {min_price:.2f}')\n",
    "ax2.axvline(max_price, color='green', linestyle='dashed', linewidth=2, label=f'Máximo: {max_price:.2f}')\n",
    "ax2.legend()\n",
    "# Histograma de 'metascore' en el segundo subplot\n",
    "sns.histplot(steam_eda_reduc['metascore'], bins=100, kde=False, color='gray', ax=ax1)\n",
    "min_metascore = steam_eda_reduc['metascore'].min()\n",
    "max_metascore = steam_eda_reduc['metascore'].max()\n",
    "ax1.set_xlabel('Metascore')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "ax1.set_title('Histograma del Metascore de los Videojuegos')\n",
    "ax1.text(0.75, 0.9, f\"Media: {steam_eda_reduc['metascore'].mean():.2f}\\nMediana: {steam_eda_reduc['metascore'].median():.2f}\\nDesviación Estándar: {steam_eda_reduc['metascore'].std():.2f}\",\n",
    "         transform=ax1.transAxes)\n",
    "ax1.axvline(min_metascore, color='red', linestyle='dashed', linewidth=2, label=f'Mínimo: {min_metascore:.2f}')\n",
    "ax1.axvline(max_metascore, color='green', linestyle='dashed', linewidth=2, label=f'Máximo: {max_metascore:.2f}')\n",
    "ax1.legend()\n",
    "# Ajustamos los subplots para evitar superposición de etiquetas\n",
    "plt.tight_layout()\n",
    "# Mostramos el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ambos histogramas resultan muy claros a la lectura, no obstante ser notorios como la mayoria de los gaps en la variables metascore parecieran aparecen cada tres marcas de puntajes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatterplot para las variables 'price' y 'metascore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el scatter plot para las variables de interés\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=data_steam, x='metascore', y='price', size='price', sizes=(30, 120), palette='viridis', alpha=0.7, legend=False)\n",
    "plt.xlabel('Metascore')\n",
    "plt.ylabel('Precio')\n",
    "plt.title('Scatter Plot: Metascore vs Precio')\n",
    "# Agregamos una la línea de varianza\n",
    "reg_plot = sns.regplot(data=data_steam, x='metascore', y='price', scatter=False, color='red')\n",
    "# Obtenenemos los resultados de la regresión lineal\n",
    "x = data_steam['metascore']\n",
    "y = data_steam['price']\n",
    "model = sns.regplot(data=data_steam, x='metascore', y='price', scatter=False, color='red')\n",
    "slope, intercept = model.get_lines()[0].get_data()\n",
    "# Imprimimos los resultados de la regresión lineal\n",
    "print(f\"Coeficiente de la línea de regresión (pendiente): {slope[1]:.2f}\")\n",
    "print(f\"Término independiente de la línea de regresión (intercepto): {intercept[1]:.2f}\")\n",
    "# Mostramos el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con lo visualizado, podemos concluir que para cada aumento de una unidad en el metascore, el precio del juego aumenta en promedio en 20.77 unidades, teniendo como punto de partida que cuando el metascore sea cero, el precio sería de aproximadamente 6.86 unidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplot entre las variables 'price', 'metascore' y 'early_access'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el boxplot de las variables de interés  \n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.boxplot(data=steam_eda_reduc, x='price', y='metascore', hue='early_access')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Claro resulta, luego del boxplot, que se presentan valores únicos y atípicos, en general, en unidades de metascore por debajo de 60 en la mayoría de las unidades de precio, manteniéndose un constante volumen de puntajes entre los 65 y 80 puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplot entre las variables 'genres', 'price' y 'early_access'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el boxplot de las variables de interés  \n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.boxplot(data=steam_eda_reduc, x='genres', y='price', hue='early_access')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Es interesante ver, en este segundo boxplot que, al comparar los géneros con el precio, la visualización se invierte -en relación al boxplot anterior- casi a un 100%. Aquí observamos que los valores únicos o atípicos se dan por encima de los 20 puntos de precio, generándose la mayor concentración entre los 10 y los 25. Como punto de atención, es llamativo ver que en los géneros Free To Play, el volumen de precios es más elevado que en los demás géneros. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
